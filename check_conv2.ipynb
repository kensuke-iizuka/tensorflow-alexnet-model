{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate input data and weights for conv2 in AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate random data for input\n",
    "input = np.random.rand(96 * 27 * 27).astype(np.float32)\n",
    "tf_input = input.reshape([1, 27, 27, 96])\n",
    "\n",
    "## Write input data as binary\n",
    "fpga_input = tf_input.transpose([0, 3, 1, 2]).flatten()\n",
    "byte_data = fpga_input.tobytes()\n",
    "with open('conv2_fpga_in.bin', 'wb') as f:\n",
    "    f.write(byte_data)\n",
    "with open('conv2_fpga_in.txt', 'w') as f:\n",
    "    for v in fpga_input:\n",
    "        f.write(\"{}\\n\".format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Load weights and bias for convolution2 in AlexNet(from ONNX)\n",
    "load_data = np.fromfile('conv2_fpga_in.bin', dtype = np.float32)\n",
    "tf_load_input = load_data.reshape([1, 96 ,27, 27]).transpose([0, 2, 3, 1])\n",
    "onnx_weight = np.load('conv2_w_0.npy', allow_pickle=True, encoding='bytes').astype(np.float32)\n",
    "onnx_bias = np.load('conv2_b_0.npy', allow_pickle=True, encoding='bytes').astype(np.float32)\n",
    "tf_weight = onnx_weight.transpose([2, 3, 1, 0]) # NCHW to NHWC\n",
    "print(np.array_equal(tf_load_input, tf_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define group convolution and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define group convolution\n",
    "def conv(x, weights, biases, stride_y, stride_x, name,\n",
    "         padding='SAME', groups=1):\n",
    "\n",
    "    # Create lambda function for the convolution\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k,\n",
    "                                         strides=[1, stride_y, stride_x, 1],\n",
    "                                         padding=padding)\n",
    "\n",
    "    if groups == 1:\n",
    "        conv = convolve(x, weights)\n",
    "\n",
    "    # In the cases of multiple groups, split inputs & weights and\n",
    "    else:\n",
    "        # Split input and weights and convolve them separately\n",
    "        input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)\n",
    "        weight_groups = tf.split(axis=3, num_or_size_splits=groups,\n",
    "                                 value=weights)\n",
    "        output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\n",
    "\n",
    "        # Concat the convolved output together again\n",
    "        conv = tf.concat(axis=3, values=output_groups)\n",
    "\n",
    "    # Add biases\n",
    "    bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 27, 27, 256)\n",
      "(1, 256, 27, 27)\n"
     ]
    }
   ],
   "source": [
    "# Run convolution\n",
    "\n",
    "stride = 1\n",
    "pad = 2\n",
    "padding = [[0, 0], [pad, pad], [pad, pad], [0, 0]]\n",
    "output = conv(tf_input, tf_weight, onnx_bias, 1, 1, padding=padding, name='group_test_conv', groups=2)\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    tf_out = sess.run(output)\n",
    "    print(type(tf_out))\n",
    "    print(tf_out.shape)\n",
    "    result = tf_out.transpose([0, 3, 1, 2])# NHWC to NCHW\n",
    "    print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6047369\n"
     ]
    }
   ],
   "source": [
    "## Write the result as binary data binary data format is NCHW\n",
    "byte_data = result.flatten()\n",
    "print(byte_data[0])\n",
    "byte_data = byte_data.tobytes()\n",
    "with open('tf_conv2_out.bin', 'wb') as f:\n",
    "    f.write(byte_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare fpga result with tf result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpga_result = np.fromfile('fpga_conv2_out.bin', dtype = np.float32)\n",
    "tf_result = np.fromfile('tf_conv2_out.bin', dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error is somewhere...\n",
      "(186624,)\n",
      "0.6047369\n",
      "0.6047369\n"
     ]
    }
   ],
   "source": [
    "if(fpga_result.shape != tf_result.shape):\n",
    "    print(\"The size of weight is wrong\")\n",
    "    print(\"FPGA:: \", fpga_result.shape)\n",
    "    print(\"TF:: \", tf_result.shape)\n",
    "if(fpga_result.dtype != tf_result.dtype):\n",
    "    print(\"The data type of bias is wrong\")\n",
    "if not np.array_equal(fpga_result, tf_result):\n",
    "    print(\"error is somewhere...\")\n",
    "print(fpga_result.shape)\n",
    "print(fpga_result[0])\n",
    "print(tf_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max err index:  46902 \n",
      "Error value:  4.7270441e-07 \n",
      "Error rate:  0.07217897 \n",
      "TF result:  -6.5490603e-06 \n",
      "FPGA result:  -6.076356e-06\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i, e in enumerate(fpga_result):\n",
    "    error = abs(tf_result[i] - fpga_result[i])\n",
    "    errors.append(error)\n",
    "\n",
    "error_ratio = [abs(e[0]/e[1]) for e in zip(errors, tf_result)]\n",
    "error_ratio = np.array(error_ratio, dtype=np.float32)\n",
    "                  \n",
    "mi = error_ratio.argmax()ã€€\n",
    "print(\"Max err index: \", mi, \"\\nError value: \", errors[mi], \"\\nError rate: \", error_ratio[mi], \"\\nTF result: \",tf_result[mi], \"\\nFPGA result: \", fpga_result[mi])\n",
    "cnt = 0\n",
    "for i, err in enumerate(error_ratio):\n",
    "    if err > 1.0e-03:\n",
    "        cnt = cnt+1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1077417\n",
      "-1.1077412\n"
     ]
    }
   ],
   "source": [
    "print(fpga_result[134110])\n",
    "print(tf_result[134110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11679\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i, e in enumerate(errors):\n",
    "    if e > 1.0e-6:\n",
    "#         print(\"index: \", i, \" error: \", e)\n",
    "        cnt = cnt + 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-tf",
   "language": "python",
   "name": "python3-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
